@article{ARBELAITZ2013243,
    title = {An extensive comparative study of cluster validity indices},
    journal = {Pattern Recognition},
    volume = {46},
    number = {1},
    pages = {243-256},
    year = {2013},
    issn = {0031-3203},
    doi = {https://doi.org/10.1016/j.patcog.2012.07.021},
    url = {https://www.sciencedirect.com/science/article/pii/S003132031200338X},
    author = {Olatz Arbelaitz and Ibai Gurrutxaga and Javier Muguerza and Jesús M. Pérez and Iñigo Perona},
    keywords = {Crisp clustering, Cluster validity index, Comparative analysis},
    abstract = {The validation of the results obtained by clustering algorithms is a fundamental part of the clustering process. The most used approaches for cluster validation are based on internal cluster validity indices. Although many indices have been proposed, there is no recent extensive comparative study of their performance. In this paper we show the results of an experimental work that compares 30 cluster validity indices in many different environments with different characteristics. These results can serve as a guideline for selecting the most suitable index for each possible application and provide a deep insight into the performance differences between the currently available indices.}
}

@inproceedings{CVI_Survey_Garcia,
    author = {Jos\'{e}-Garc\'{\i}a, Ad\'{a}n and G\'{o}mez-Flores, Wilfrido},
    title = {A Survey of Cluster Validity Indices for Automatic Data Clustering Using Differential Evolution},
    year = {2021},
    isbn = {9781450383509},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3449639.3459341},
    doi = {10.1145/3449639.3459341},
    abstract = {In cluster analysis, the automatic clustering problem refers to the determination of both the appropriate number of clusters and the corresponding natural partitioning. This can be addressed as an optimization problem in which a cluster validity index (CVI) is used as a fitness function to evaluate the quality of potential solutions. Different CVIs have been proposed in the literature, aiming to identify adequate cluster solutions in terms of intracluster cohesion and intercluster separation. However, it is important to identify the scenarios in which these CVIs perform well and their limitations. This paper evaluates the effectiveness of 22 different CVIs used as fitness functions in an evolutionary clustering algorithm named ACDE based on differential evolution. Several synthetic datasets are considered: linearly separable data having both well-separated and overlapped clusters, and non-linearly separable data having arbitrarily-shaped clusters. Besides, real-life datasets are also considered. The experimental results indicate that the Silhouette index consistently reached an acceptable performance in linearly separable data. Furthermore, the indices Calinski-Harabasz, Davies-Bouldin, and generalized Dunn obtained an adequate clustering performance in synthetic and real-life datasets. Notably, all the evaluated CVIs performed poorly in clustering the non-linearly separable data because of the assumptions about data distributions.},
    booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
    pages = {314-322},
    numpages = {9},
    keywords = {cluster validity index, automatic clustering, differential evolution},
    location = {Lille, France},
    series = {GECCO '21}
}

@Manual{R_dtwclust,
    title = {Time Series Clustering Along with Optimizations for the Dynamic Time Warping Distance},
    author = {Alexis Sarda-Espinosa},
    year = {2022},
    note = {R package version 5.5.10},
    url = {https://cran.r-project.org/package=dtwclust},
}

@misc{cvik-toolbox-GitHub,
    title = {Cluster Validity Index Toolbox},
    author = {Ad\'{a}n Jos\'{e}-Garc\'{\i}a},
    year = {2021},
    url = {https://github.com/adanjoga/cvik-toolbox}
}

@article{brito_da_silva_incremental_2020,
	title = {Incremental Cluster Validity Indices for Online Learning of Hard Partitions: Extensions and Comparative Study},
	volume = {8},
	doi = {10.1109/ACCESS.2020.2969849},
	abstract = {Validation is one of the most important aspects of clustering, particularly when the user is designing a trustworthy or explainable system. However, most clustering validation approaches require batch calculation. This is an important gap because of the value of clustering in real-time data streaming and other online learning applications. Therefore, interest has grown in providing online alternatives for validation. This paper extends the incremental cluster validity index (iCVI) family by presenting incremental versions of Calinski-Harabasz (iCH), Pakhira-Bandyopadhyay-Maulik (iPBM), WB index (iWB), Silhouette (iSIL), Negentropy Increment (iNI), Representative Cross Information Potential (irCIP), Representative Cross Entropy (irH), and Conn\_Index (iConn\_Index). This paper also provides a thorough comparative study of correct, under- and over-partitioning on the behavior of these iCVIs, the Partition Separation (PS) index as well as four recently introduced iCVIs: incremental Xie-Beni (iXB), incremental Davies-Bouldin (iDB), and incremental generalized Dunn's indices 43 and 53 (iGD43 and iGD53). Experiments were carried out using a framework that was designed to be as agnostic as possible to the clustering algorithms. The results on synthetic benchmark data sets showed that while evidence of most under-partitioning cases could be inferred from the behaviors of the majority of these iCVIs, over-partitioning was found to be a more challenging problem, detected by fewer of them. Interestingly, over-partitioning, rather then under-partitioning, was more prominently detected on the real-world data experiments within this study. The expansion of iCVIs provides significant novel opportunities for assessing and interpreting the results of unsupervised lifelong learning in real-time, wherein samples cannot be reprocessed due to memory and/or application constraints.},
	number = {i},
	journal = {IEEE Access},
	author = {Brito Da Silva, Leonardo Enzo and Melton, Niklas Max and Wunsch, Donald C.},
	year = {2020},
	keywords = {Clustering, adaptive resonance theory (ART), data streams, incremental (online) clustering algorithms, incremental cluster validity index (iCVI), validation},
	pages = {22025--22047},
}

@article{Grossberg2013,
    title = {Adaptive Resonance Theory: How a brain learns to consciously attend, learn, and recognize a changing world},
    year = {2013},
    journal = {Neural Networks},
    author = {Grossberg, Stephen},
    pages = {1--47},
    volume = {37},
    publisher = {Elsevier Ltd},
    url = {http://dx.doi.org/10.1016/j.neunet.2012.09.017},
    doi = {10.1016/j.neunet.2012.09.017},
    issn = {08936080},
    pmid = {23149242},
    keywords = {Adaptive Resonance Theory, Adaptive timing, Amygdala, Attention, Basal ganglia, Consciousness, Entorhinal cortex, Expectation, Gamma and beta oscillations, Hippocampal cortex, Inferotemporal cortex, Learning, Parietal cortex, Prefrontal cortex, Recognition, Reinforcement learning, Speech perception, Synchrony, Working memory}
}

@article{Grossberg1980,
    title = {How Does a Brain Build a Cognitive Code?},
    year = {1980},
    journal = {Psychological Review},
    author = {Grossberg, Stephen},
    number = {1},
    month = {1},
    pages = {1--51},
    volume = {87},
    doi = {10.1037/0033-295X.87.1.1},
    issn = {0033295X},
    keywords = {competition between afferent data vs learned feedb}
}

@article{DaSilva2019,
    title = {A Survey of Adaptive Resonance Theory Neural Network Models for Engineering Applications},
    year = {2019},
    journal = {Neural Networks},
    author = {Brito da Silva, Leonardo Enzo and Elnabarawy, Islam and Wunsch, Donald C.},
    pages = {167--203},
    volume = {120},
    publisher = {Elsevier Ltd},
    url = {https://doi.org/10.1016/j.neunet.2019.09.012 http://arxiv.org/abs/1905.11437},
    doi = {10.1016/j.neunet.2019.09.012},
    issn = {0893-6080},
    arxivId = {1905.11437},
    keywords = {Adaptive resonance theory, Classification, Clustering, Regression, Reinforcement learning, Survey, adaptive resonance theory, classification, clustering, corresponding author, explainable, neural networks, regression, reinforcement learning, survey, unsupervised learning}
}